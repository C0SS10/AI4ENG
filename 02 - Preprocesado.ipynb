{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqO6FiIFj4QqzzuxihLMIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/E-CG/AI4ENG/blob/master/02%20-%20Preprocesado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ“¦ Librerias y paquetes para la ejecuciÃ³n del notebook.**"
      ],
      "metadata": {
        "id": "SQMZNxAKf-DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install py7zr"
      ],
      "metadata": {
        "id": "LIrDDyQt4B4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sjCzU3AA4EGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "c3cp8sLH4Hhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "# AquÃ­ debes cambiar la direcciÃ³n donde tengas tus credenciales de Kaggle\n",
        "! cp /content/drive/MyDrive/Modelos_I/credentials_kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "bnhCnURT4IRT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download favorita-grocery-sales-forecasting\n",
        "! unzip favorita-grocery-sales-forecasting.zip"
      ],
      "metadata": {
        "id": "k3V3m-V34IGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W3Q7y5Uyredt"
      },
      "outputs": [],
      "source": [
        "# Librerias uso bÃ¡sico\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math as m\n",
        "import time\n",
        "import py7zr\n",
        "import os\n",
        "from subprocess import check_output\n",
        "\n",
        "# Librerias preprocesado\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "\n",
        "# Librerias para grÃ¡ficar\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Funciones de sklearn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression,SGDRegressor,ElasticNet,Ridge\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ—‚ï¸Leyendo y extrayendo los archivos .csv**"
      ],
      "metadata": {
        "id": "47YvvSlDf_V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo 7z en Google Drive\n",
        "sevenzip_file_path = '/content'\n",
        "\n",
        "# Directorio de destino para la extracciÃ³n\n",
        "extracted_dir = '/content/extracted_data/'\n",
        "\n",
        "# Crear el directorio de destino si no existe\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Listar los archivos .7z en el directorio de entrada\n",
        "files_to_extract = [file for file in os.listdir(sevenzip_file_path) if file.endswith('.7z')]\n",
        "\n",
        "# Iterar a travÃ©s de los archivos y descomprimirlos\n",
        "for file_to_extract in files_to_extract:\n",
        "    with py7zr.SevenZipFile(os.path.join(sevenzip_file_path, file_to_extract), mode='r') as z:\n",
        "        z.extractall(path=extracted_dir)"
      ],
      "metadata": {
        "id": "BCCuI9R04NGr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores = pd.read_csv('/content/extracted_data/stores.csv')\n",
        "items = pd.read_csv('/content/extracted_data/items.csv')\n",
        "holidays_e = pd.read_csv('/content/extracted_data/holidays_events.csv', parse_dates=[\"date\"])\n",
        "transactions = pd.read_csv('/content/extracted_data/transactions.csv', parse_dates=[\"date\"])\n",
        "oil = pd.read_csv('/content/extracted_data/oil.csv')\n",
        "\n",
        "# Cargar el archivo de entrenamiento en chunks\n",
        "chunked_dfs = pd.read_csv(\"/content/extracted_data/train.csv\",\n",
        "                          chunksize=20000,\n",
        "                          usecols=[1, 2, 3, 4, 5],\n",
        "                          parse_dates=['date'],\n",
        "                          low_memory=False)\n",
        "\n",
        "print('Archivos cargados ðŸ—žï¸âœ…')"
      ],
      "metadata": {
        "id": "Q02HSAsN4Rrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3404816f-3eca-43bd-a6ac-3be05105ee45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos cargados ðŸ—žï¸âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **âŒÂ¿QuÃ© archivos tienen datos nulos?**"
      ],
      "metadata": {
        "id": "Ya62btbjgNok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ–Šï¸ Se toma cada columna del dataframe en cuestion, se suman la cantidad de registros NaN y se convierte en un **porcentaje**. A cada columna se le saca tal porcentaje."
      ],
      "metadata": {
        "id": "pfodpXAhhVso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oil_nan = (oil.isnull().sum() / oil.shape[0]) * 100\n",
        "oil_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeGTJKOAPc8T",
        "outputId": "46433aad-9053-4fa8-aaf3-265167139259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date          0.000000\n",
              "dcoilwtico    3.530378\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay un 3.5% de datos faltantes en el archivo (oil.csv)"
      ],
      "metadata": {
        "id": "JWpoOz8FR04R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_nan = (stores.isnull().sum() / stores.shape[0]) * 100\n",
        "store_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfusvuMbR87_",
        "outputId": "35bbb8d6-e6b5-47bf-db3b-b81480f9ffb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "store_nbr    0.0\n",
              "city         0.0\n",
              "state        0.0\n",
              "type         0.0\n",
              "cluster      0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay datos faltantes en (stores.csv)"
      ],
      "metadata": {
        "id": "MMQexb4KhuFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_nan = (items.isnull().sum() / items.shape[0]) * 100\n",
        "item_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrxJ-uYAVDPx",
        "outputId": "fc748161-6764-46a5-ef35-0f03da7f7460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "item_nbr      0.0\n",
              "family        0.0\n",
              "class         0.0\n",
              "perishable    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay datos faltantes en (items.csv)"
      ],
      "metadata": {
        "id": "iE8ySU4qhzH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "holiday_nan = (holidays_e.isnull().sum() / holidays_e.shape[0]) * 100\n",
        "holiday_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXN_5LowiodF",
        "outputId": "da13621c-03fa-408b-9b4e-814418082997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date           0.0\n",
              "type           0.0\n",
              "locale         0.0\n",
              "locale_name    0.0\n",
              "description    0.0\n",
              "transferred    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay datos nulo en el archivo (holidays_events.csv)"
      ],
      "metadata": {
        "id": "V-xEPFzKod73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tran_nan = (transactions.isnull().sum() / transactions.shape[0]) * 100\n",
        "tran_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30c0tYWuiwZ5",
        "outputId": "cc2de6a9-5259-4b9e-fb5e-fd36ceb4cfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date            0.0\n",
              "store_nbr       0.0\n",
              "transactions    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay datos faltantes en (transactions.csv)"
      ],
      "metadata": {
        "id": "aDerSZvNojXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ¦¾Primeras predicciones**"
      ],
      "metadata": {
        "id": "IPbxvbgkgV7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomar 1 tienda por estado en las fechas mayores a 2016 y predecir las ventas unitarias de todos los productos."
      ],
      "metadata": {
        "id": "ZY1IKwvBZ6zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por estado y obtener el primer store_nbr en cada estado\n",
        "tienda_por_estado = stores.groupby('state')['store_nbr'].first()\n",
        "tienda_por_estado"
      ],
      "metadata": {
        "id": "0dYx3fJyZrm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c28c8bd-d137-4f89-f0b2-12dee4c60f85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state\n",
              "Azuay                             37\n",
              "Bolivar                           19\n",
              "Chimborazo                        14\n",
              "Cotopaxi                          12\n",
              "El Oro                            40\n",
              "Esmeraldas                        43\n",
              "Guayas                            24\n",
              "Imbabura                          15\n",
              "Loja                              38\n",
              "Los Rios                          31\n",
              "Manabi                            52\n",
              "Pastaza                           22\n",
              "Pichincha                          1\n",
              "Santa Elena                       25\n",
              "Santo Domingo de los Tsachilas     5\n",
              "Tungurahua                        23\n",
              "Name: store_nbr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar una lista para almacenar los DataFrames filtrados\n",
        "datos_filtrados = []\n",
        "\n",
        "# Iterar a travÃ©s de los chunks\n",
        "for chunk in chunked_dfs:\n",
        "    # Crear una mÃ¡scara booleana para las tiendas seleccionadas\n",
        "    mask_tiendas = chunk['store_nbr'].isin(stores['store_nbr'])\n",
        "    # Crear una mÃ¡scara booleana para las fechas entre 2016-01-01 a 2016-12-31\n",
        "    mask = (chunk['date'] >= '2016-01-01') & (chunk['date'] <= '2016-12-31') & chunk['store_nbr'].isin(tienda_por_estado)\n",
        "\n",
        "    # Aplicar la mÃ¡scara y agregar las filas filtradas a la lista\n",
        "    trozo_filtrado = chunk[mask]\n",
        "    datos_filtrados.append(trozo_filtrado)\n",
        "\n",
        "# Concatenar los DataFrames filtrados en uno solo\n",
        "train_store_state = pd.concat(datos_filtrados, ignore_index=True)"
      ],
      "metadata": {
        "id": "41bFYCaWWNqs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_nan = (train_store_state.isnull().sum() / train_store_state.shape[0]) * 100\n",
        "train_nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AivovsRBWhpB",
        "outputId": "9eb1c2a9-59e0-4834-ad1b-1c09366b45f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date           0.0\n",
              "store_nbr      0.0\n",
              "item_nbr       0.0\n",
              "unit_sales     0.0\n",
              "onpromotion    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay datos nulos en el dataframe de entrenamiento"
      ],
      "metadata": {
        "id": "tPOCSRRzb5na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ’±Convirtiendo datos para que la mÃ¡quina lo pueda entender.**"
      ],
      "metadata": {
        "id": "5c0ygPsBTYDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convirtiendo las fechas\n",
        "train_store_state['date'] = pd.to_datetime(train_store_state['date'])\n",
        "holidays_e['date'] = pd.to_datetime(holidays_e['date'])\n",
        "oil['date'] = pd.to_datetime(oil['date'])"
      ],
      "metadata": {
        "id": "KQnpYdL-WnKv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas que no son importantes para las predicciones\n",
        "# No presentan ningun efecto, ni relaciÃ³n (VeÃ¡se la exploraciÃ³n de datos.)\n",
        "stores.drop(columns=['state', 'type', 'cluster'], inplace= True)\n",
        "\n",
        "''' Si el dÃ­a no es festivo se considera normal.\n",
        "Si no es festivo nacional o local, tambiÃ©n se considera normal. '''\n",
        "holidays_e.drop(columns = ['locale_name', 'description', 'transferred'], inplace = True)"
      ],
      "metadata": {
        "id": "LjDsfqcynHbH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ“„Juntando los demÃ¡s archivos en train.csv y generando dataframes de prueba y entrenamiento**"
      ],
      "metadata": {
        "id": "hjfgQOiFglzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MergeDataTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # Constructor de la clase\n",
        "        print(\"Inicializando MergeDataTransformer\")\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Este mÃ©todo no realiza ningÃºn ajuste de datos, por lo que simplemente devuelve 'self'\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Realiza la fusiÃ³n de DataFrames\n",
        "        X = pd.merge(pd.merge(pd.merge(X, stores, on='store_nbr', how='left'),\n",
        "                             oil, on='date', how='left'),\n",
        "                             holidays_e, on='date', how='left')\n",
        "\n",
        "        # Ordena los datos por fecha\n",
        "        X = X.sort_values('date')\n",
        "\n",
        "        # Reemplazando NaNs en oil.csv\n",
        "        X.dcoilwtico = X.dcoilwtico.fillna(method='bfill', axis=0).fillna(0)\n",
        "\n",
        "        # Llena los valores nulos en 'type' y 'locale' con 'Normal'\n",
        "        X.type = X.type.fillna('Normal')\n",
        "        X.locale = X.locale.fillna('Normal')\n",
        "\n",
        "        # Aplica la codificaciÃ³n one-hot a las columnas categÃ³ricas especificadas\n",
        "        encoder = OneHotEncoder()\n",
        "        categorical_cols = ['store_nbr', 'item_nbr', 'onpromotion', 'city', 'type', 'locale']\n",
        "\n",
        "        encoder.fit(X[categorical_cols])\n",
        "        encoded_cols = encoder.transform(X[categorical_cols]).toarray()\n",
        "        encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "        # Concatena los datos codificados one-hot con el DataFrame original\n",
        "        X = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "\n",
        "        # Restablece el Ã­ndice del DataFrame resultante y elimina la columna 'index'\n",
        "        data = X.reset_index().drop(columns='index')\n",
        "\n",
        "        # Devuelve el DataFrame resultante\n",
        "        return data"
      ],
      "metadata": {
        "id": "xFYQT8yXbu_h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitDataTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # Constructor de la clase\n",
        "        print(\"Inicializando SplitDataTransformer\")\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Este mÃ©todo no realiza ningÃºn ajuste de datos, por lo que simplemente devuelve 'self'\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Extrae la columna 'unit_sales' como el objetivo 'y' y elimina esta columna de 'X'\n",
        "        y = X.pop('unit_sales')\n",
        "\n",
        "        # Divide los datos en conjuntos de entrenamiento y prueba (90% de entrenamiento, 10% de prueba)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "        # Establece la columna 'date' como el Ã­ndice en los conjuntos de entrenamiento y prueba\n",
        "        X_train = X_train.set_index('date')\n",
        "        X_test = X_test.set_index('date')\n",
        "\n",
        "        # Devuelve los conjuntos de entrenamiento y prueba, asÃ­ como los objetivos de entrenamiento y prueba\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "taD-IANHcnsO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('merge_data', MergeDataTransformer()),\n",
        "    ('split_data', SplitDataTransformer())\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo68rPf9cqY8",
        "outputId": "3971844f-3097-4e8d-e981-61372869ab9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializando MergeDataTransformer\n",
            "Inicializando SplitDataTransformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar aleatoriamente 80,000 filas de 'train_store_state'\n",
        "train_sample = train_store_state.sample(n=78000)\n",
        "\n",
        "# Obtener los identificadores Ãºnicos de los productos en el conjunto de muestra\n",
        "productos_sample = train_sample['item_nbr'].unique()\n",
        "\n",
        "# Tomar los primeros 3 productos Ãºnicos\n",
        "productos_sample = productos_sample[:3]"
      ],
      "metadata": {
        "id": "zeVIXeA0gDLK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = pipeline.fit_transform(train_sample)"
      ],
      "metadata": {
        "id": "ifeOG1pVcxao"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viendo los conjuntos de prueba y entrenamiento"
      ],
      "metadata": {
        "id": "EiJSYggzQfRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "id": "wS3d1WWnQiEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head(2)"
      ],
      "metadata": {
        "id": "e682zQ8oQknR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head(2)"
      ],
      "metadata": {
        "id": "68V04mVsQmd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.head(2)"
      ],
      "metadata": {
        "id": "NmPphuPaQqpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”ŽUtilizando algunos modelos para hacer las primeras predicciones**"
      ],
      "metadata": {
        "id": "8zQGzQW5Xz3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiendo una funciÃ³n para evaluar el rendimiento de cada modelo a utilizar\n",
        "def checkModelPerformane(model):\n",
        "  # Entrenar el modelo con los datos de entrenamiento\n",
        "  model.fit(X_train.values, y_train.values)\n",
        "\n",
        "  # Realizar predicciones en el conjunto de prueba\n",
        "  predictions = model.predict(X_test.values)\n",
        "\n",
        "  # Calcular y mostrar el error cuadrÃ¡tico medio (RMSE) de las predicciones\n",
        "  rmse = np.sqrt(mean_squared_error(y_test.values, predictions))\n",
        "  print(\"Root Mean Squared Error (RMSE): \", rmse)\n",
        "\n",
        "  # Calcular y mostrar el error absoluto medio (MAE) de las predicciones\n",
        "  mae = np.sqrt(mean_absolute_error(y_test.values, predictions))\n",
        "  print(\"Root Mean Absolute Error (MAE): \", mae)"
      ],
      "metadata": {
        "id": "-ak81fCVw_fV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menores valores en el estadistico de error, mejor serÃ¡ el modelo."
      ],
      "metadata": {
        "id": "RyBZK83ELmb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LinearRegression\")\n",
        "checkModelPerformane(LinearRegression())"
      ],
      "metadata": {
        "id": "1f8iKu0ixGnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0af0f70-0168-4ad6-c229-dbe5d8fd9b51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression\n",
            "Root Mean Squared Error (RMSE):  9489713153.762894\n",
            "Root Mean Absolute Error (MAE):  13224.865445601821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SGDRegressor\")\n",
        "checkModelPerformane(SGDRegressor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocHKgAefPh8S",
        "outputId": "d0433191-e09e-48e9-f948-f22d899f97c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDRegressor\n",
            "Root Mean Squared Error (RMSE):  48486333.30887891\n",
            "Root Mean Absolute Error (MAE):  4705.666659393304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ElasticNet\")\n",
        "checkModelPerformane(ElasticNet())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4yOEIGaPoUS",
        "outputId": "f4e15a88-d32b-438c-c84c-c63b7f10f68f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "Root Mean Squared Error (RMSE):  10.594168981160163\n",
            "Root Mean Absolute Error (MAE):  2.296691744213001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ridge\")\n",
        "checkModelPerformane(Ridge())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa6nyRXgNq-h",
        "outputId": "d228eefe-e94a-4178-c47a-75676c1bf68f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge\n",
            "Root Mean Squared Error (RMSE):  11.363234521196532\n",
            "Root Mean Absolute Error (MAE):  2.3523794464919305\n"
          ]
        }
      ]
    }
  ]
}